<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>Jonathan Flores Monroy | Research</title>
    <link rel="stylesheet" href="style_2.css">
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;700&family=Playfair+Display:wght@700&display=swap" rel="stylesheet">
</head>
<body>

    <nav class="navbar">
        <div class="logo">J. FLORES <span>PhD</span></div>
            <ul class="nav-links">
                
                <li><a href="#video-hero">Home</a></li>
                <li><a href="#papersContainer">Scientific Publications</a></li>
                <!-- <li><a href="#achievements">Achievements</a></li> <li><a href="#projects">Projects</a></li> -->
                <!-- <li><a href="#speakers">Talks</a></li> -->
                <li><a href="#db-section">Databases</a></li>
                <li><a href="index.html">About Me</a></li>
            </ul>
    </nav>

    <section id="video-hero" class="hero">
        <div class="video-container">
            <video autoplay muted loop playsinline>
                <source src="videos/video_1.mp4" type="video/mp4">
                Tu navegador no soporta video.
            </video>
            <div class="video-overlay">
                <h1>Video Anomaly Detection</h1>
                <p>Advancing real-time security through GNN & Temporal Modeling</p>
            </div>
        </div>
    </section>

    <section class="objective">
        <p>Mi investigaci√≥n se centra en el desarrollo de arquitecturas de Deep Learning capaces de modelar comportamientos complejos en entornos din√°micos, optimizando la precisi√≥n y la eficiencia computacional.</p>
    </section>

    <section class="quick-nav">
        <a href="#latest-results" class="nav-card">
            <h3>Latest Results</h3>
            <span>Ver m√©tricas SOTA</span>
        </a>
        <a href="#papers" class="nav-card">
            <h3>Publications</h3>
            <span>Archive completo</span>
        </a>
        <a href="#db-section" class="nav-card">
            <h3>Databases</h3>
            <span>Custom Datasets</span>
        </a>
        <a href="#awards" class="nav-card"> <h3>Achievements</h3>
            <span>Patents & Awards</span>
        </a>
        <a href="#speakers" class="nav-card">
            <h3>Talks</h3>
            <span>Conferencias Mundiales</span>
        </a>
        
    </section>

    <section id="latest-results" class="research-section">
        <h2 class="section-title">Deep Dive: TransLowNet Results</h2>

        <div class="research-row">
            <div class="res-text">
                <h3>Eficiencia en Baja Iluminaci√≥n</h3>
                <p>Utilizando X3D como backbone, logramos una reducci√≥n del 15% en falsos positivos en escenarios nocturnos comparado con modelos tradicionales.</p>
            </div>
            <div class="res-visual">
                <img src="figuresPapers/fig1.png" alt="Gr√°fica de precisi√≥n">
            </div>
        </div>

        <div class="research-row reverse">
            <div class="res-text">
                <h3>Arquitectura GAT-based</h3>
                <p>La integraci√≥n de Graph Attention Networks permite capturar la relaci√≥n entre m√∫ltiples actores en la escena, mejorando la detecci√≥n de eventos de violencia.</p>
            </div>
            <div class="res-visual">
                <img src="figuresPapers/fig2.png" alt="Diagrama de red neuronal">
            </div>
        </div>

        
        <div class="research-row">
            <div class="res-text">
                <h3>Eficiencia en Baja Iluminaci√≥n</h3>
                <p>Utilizando X3D como backbone, logramos una reducci√≥n del 15% en falsos positivos en escenarios nocturnos comparado con modelos tradicionales.</p>
            </div>
            <div class="res-visual">
                <img src="figuresPapers/fig3.png" alt="Gr√°fica de precisi√≥n">
            </div>
        </div>

        <div class="research-row reverse">
            <div class="res-text">
                <h3>Arquitectura GAT-based</h3>
                <p>La integraci√≥n de Graph Attention Networks permite capturar la relaci√≥n entre m√∫ltiples actores en la escena, mejorando la detecci√≥n de eventos de violencia.</p>
            </div>
            <div class="res-visual">
                <img src="figuresPapers/fig4.png" alt="Diagrama de red neuronal">
            </div>
        </div>
        
        <div class="cta-container">
            <a href="#" class="btn-main">Leer Paper Completo (MDPI)</a>
        </div>
    </section>


    
        <section id="papers" class="papers-section">
            <h2 class="section-title">Scientific Publications</h2>
            <p class="section-subtitle">A collection of 13+ peer-reviewed papers focusing on Computer Vision & Anomaly Detection.</p>

            <div class="papers-controls">
                <input type="text" id="paperSearch" placeholder="Search by topic (e.g. GNN, X3D)..." onkeyup="searchPapers()">
                <div class="filter-tags">
                    <span class="tag active" onclick="filterPapers('all', event)">All</span>
                    <span class="tag" onclick="filterPapers('journal', event)">Journals</span>
                    <span class="tag" onclick="filterPapers('conference', event)">Conferences</span>
                    <span class="tag" onclick="filterPapers('book', event)">Books</span>
                </div>
            </div>



            <div class="papers-list" id="papersContainer">
                
                <article class="paper-card conference" data-title="Detection Classification IEEE VAD VAR">
                    <div class="paper-info">
                        <span class="paper-venue">IEEE Xplorer ¬∑ 2025</span>
                        <h3>Detection and Classification of Abnormal Human Actions for Video Surveillance on Edge Devices</h3>
                        <p>Propuesta de un framework end-to-end dise√±ado para entornos de baja iluminaci√≥n utilizando grafos de atenci√≥n.</p>
                        <div class="paper-actions">
                            <a href="pdfPapers/Paper_1.pdf" class="paper-link pdf">PDF</a>
                            <a href="https://github.com/JonathanFlores2503/TransLowNET_FinalVersion" class="paper-link code">Code</a>
                            <!-- <button class="paper-link bib" onclick="copyBib_1()">BibTeX</button> -->
                        </div>
                    </div>
                    <div class="paper-stats">
                        <div class="stat-item">
                            <span class="stat-value">SOTA</span>
                            <span class="stat-label">Model</span>
                        </div>
                    </div>
                </article>


                <article class="paper-card journal" data-title="TransLowNet Anomaly Detection VAD VAR">
                    <div class="paper-info">
                        <span class="paper-venue">Applied Sciences ¬∑ 2025</span>
                        <h3>TransLowNet: An Online Modular Framework for Anomaly Detection in Public Transportation</h3>
                        <p>Propuesta de un framework end-to-end dise√±ado para entornos de baja iluminaci√≥n utilizando grafos de atenci√≥n.</p>
                        <div class="paper-actions">
                            <a href="pdfPapers/Paper_2.pdf" class="paper-link pdf">PDF</a>
                            <a href="https://github.com/JonathanFlores2503/TransLowNET_FinalVersion" class="paper-link code">Code</a>
                            <button class="paper-link bib" onclick="copyBib_2()">BibTeX</button>
                        </div>
                    </div>
                    <div class="paper-stats">
                        <div class="stat-item">
                            <span class="stat-value">SOTA</span>
                            <span class="stat-label">Model</span>
                        </div>
                    </div>
                </article>



                <article class="paper-card conference" data-title="Ownership authentication CLIP VQGAN">
                    <div class="paper-info">
                        <span class="paper-venue">IEEE Xplorer ¬∑ 2024</span>
                        <h3>Ownership authentication and integrity verification of digital images using generative models and custom signature</h3>
                        <p>Propuesta de un framework end-to-end dise√±ado para entornos de baja iluminaci√≥n utilizando grafos de atenci√≥n.</p>
                        <div class="paper-actions">
                            <a href="pdfPapers/Paper_3.pdf" class="paper-link pdf">PDF</a>
                            <a href="https://github.com/JonathanFlores2503/NoiseHashGAN" class="paper-link code">Code</a>
                            <button class="paper-link bib" onclick="copyBib_3()">BibTeX</button>
                        </div>
                    </div>
                    <div class="paper-stats">
                        <div class="stat-item">
                            <span class="stat-value">SOTA</span>
                            <span class="stat-label">Model</span>
                        </div>
                    </div>
                </article>




                <article class="paper-card book" data-title="Feature Extractor VAD">
                    <div class="paper-info">
                        <span class="paper-venue">IOS Press ¬∑ 2024</span>
                        <h3>Optimal Feature Extractor for Video Anomaly Detection in Public Transportation Applications</h3>
                        <p>Propuesta de un framework end-to-end dise√±ado para entornos de baja iluminaci√≥n utilizando grafos de atenci√≥n.</p>
                        <div class="paper-actions">
                            <a href="pdfPapers/Paper_4.pdf" class="paper-link pdf">PDF</a>
                            <a href="https://github.com/JonathanFlores2503/TransLowNET_FinalVersion" class="paper-link code">Code</a>
                            <button class="paper-link bib" onclick="copyBib_4()">BibTeX</button>
                        </div>
                    </div>
                    <div class="paper-stats">
                        <div class="stat-item">
                            <span class="stat-value">SOTA</span>
                            <span class="stat-label">Model</span>
                        </div>
                    </div>
                </article>



                <article class="paper-card journal" data-title="Somnolencia Distracci√≥n SOMN_IA Drowsiness Distraction">
                    <div class="paper-info">
                        <span class="paper-venue">Informaci√≥n tecnol√≥gica ¬∑ 2023</span>
                        <h3>Detecci√≥n de somnolencia y distracci√≥n en conductores y su implementaci√≥n en dispositivos m√≥viles</h3>
                        <p>Propuesta de un framework end-to-end dise√±ado para entornos de baja iluminaci√≥n utilizando grafos de atenci√≥n.</p>
                        <div class="paper-actions">
                            <a href="pdfPapers/Paper_5.pdf" class="paper-link pdf">PDF</a>
                            <!-- <a href="https://github.com/JonathanFlores2503/TransLowNET_FinalVersion" class="paper-link code">Code</a> -->
                            <button class="paper-link bib" onclick="copyBib_5()">BibTeX</button>
                        </div>
                    </div>
                    <div class="paper-stats">
                        <div class="stat-item">
                            <span class="stat-value">SOTA</span>
                            <span class="stat-label">Model</span>
                        </div>
                    </div>
                </article>




                <article class="paper-card conference" data-title="Face Expression Emociones Animo">
                    <div class="paper-info">
                        <span class="paper-venue">IEEE Xplorer ¬∑ 2023</span>
                        <h3>Face Expression Recognition using Recurrent Neural Networks</h3>
                        <p>Propuesta de un framework end-to-end dise√±ado para entornos de baja iluminaci√≥n utilizando grafos de atenci√≥n.</p>
                        <div class="paper-actions">
                            <a href="https://ieeexplore-ieee-org.bibliotecaipn.idm.oclc.org/document/10197740" class="paper-link pdf">PDF</a>
                            <a href="https://github.com/JonathanFlores2503/TransLowNET_FinalVersion" class="paper-link code">Code</a>
                            <button class="paper-link bib" onclick="copyBib_6()">BibTeX</button>
                        </div>
                    </div>
                    <div class="paper-stats">
                        <div class="stat-item">
                            <span class="stat-value">SOTA</span>
                            <span class="stat-label">Model</span>
                        </div>
                    </div>
                </article>




                <article class="paper-card journal" data-title="Detecci√≥n Emociones Animo">
                    <div class="paper-info">
                        <span class="paper-venue">P√§di ¬∑ 2022</span>
                        <h3>Detecci√≥n de estados de √°nimo en ambientes no restringidos</h3>
                        <p>Propuesta de un framework end-to-end dise√±ado para entornos de baja iluminaci√≥n utilizando grafos de atenci√≥n.</p>
                        <div class="paper-actions">
                            <a href="pdfPapers/Paper_7.pdf" class="paper-link pdf">PDF</a>
                            <!-- <a href="https://github.com/JonathanFlores2503/TransLowNET_FinalVersion" class="paper-link code">Code</a> -->
                            <button class="paper-link bib" onclick="copyBib_7()">BibTeX</button>
                        </div>
                    </div>
                    <div class="paper-stats">
                        <div class="stat-item">
                            <span class="stat-value">SOTA</span>
                            <span class="stat-label">Model</span>
                        </div>
                    </div>
                </article>




                <article class="paper-card journal" data-title="Drowsiness Distraction SOMN_IA Somnolencia Distracci√≥n">
                    <div class="paper-info">
                        <span class="paper-venue">Electronics ¬∑ 2022</span>
                        <h3>SOMN_IA: Portable and universal device for real-time detection of driver‚Äôs drowsiness and distraction levels</h3>
                        <p>Propuesta de un framework end-to-end dise√±ado para entornos de baja iluminaci√≥n utilizando grafos de atenci√≥n.</p>
                        <div class="paper-actions">
                            <a href="pdfPapers/Paper_8.pdf" class="paper-link pdf">PDF</a>
                            <!-- <a href="https://github.com/JonathanFlores2503/TransLowNET_FinalVersion" class="paper-link code">Code</a> -->
                            <button class="paper-link bib" onclick="copyBib_8()">BibTeX</button>
                        </div>
                    </div>
                    <div class="paper-stats">
                        <div class="stat-item">
                            <span class="stat-value">SOTA</span>
                            <span class="stat-label">Model</span>
                        </div>
                    </div>
                </article>




                <article class="paper-card conference" data-title="Drowsiness SOMN_IA Somnolencia">
                    <div class="paper-info">
                        <span class="paper-venue">Springer ¬∑ 2022</span>
                        <h3>A CNN-based driver‚Äôs drowsiness and distraction detection system</h3>
                        <p>Propuesta de un framework end-to-end dise√±ado para entornos de baja iluminaci√≥n utilizando grafos de atenci√≥n.</p>
                        <div class="paper-actions">
                            <a href="https://link.springer.com/chapter/10.1007/978-3-031-07750-0_8" class="paper-link pdf">PDF</a>
                            <!-- <a href="https://github.com/JonathanFlores2503/TransLowNET_FinalVersion" class="paper-link code">Code</a> -->
                            <button class="paper-link bib" onclick="copyBib_9()">BibTeX</button>
                        </div>
                    </div>
                    <div class="paper-stats">
                        <div class="stat-item">
                            <span class="stat-value">SOTA</span>
                            <span class="stat-label">Model</span>
                        </div>
                    </div>
                </article>




                <article class="paper-card book" data-title="Drowsiness SOMN_IA Somnolencia">
                    <div class="paper-info">
                        <span class="paper-venue">IOS Press ¬∑ 2022</span>
                        <h3>Implementation of a CNN-Based Driver Drowsiness and Distraction Detector in Mobile Devices</h3>
                        <p>Propuesta de un framework end-to-end dise√±ado para entornos de baja iluminaci√≥n utilizando grafos de atenci√≥n.</p>
                        <div class="paper-actions">
                            <a href="https://ebooks.iospress.nl/doi/10.3233/FAIA220258" class="paper-link pdf">PDF</a>
                            <!-- <a href="https://github.com/JonathanFlores2503/TransLowNET_FinalVersion" class="paper-link code">Code</a> -->
                            <button class="paper-link bib" onclick="copyBib_10()">BibTeX</button>
                        </div>
                    </div>
                    <div class="paper-stats">
                        <div class="stat-item">
                            <span class="stat-value">SOTA</span>
                            <span class="stat-label">Model</span>
                        </div>
                    </div>
                </article>




                <article class="paper-card conference" data-title="Drowsiness SOMN_IA Somnolencia">
                    <div class="paper-info">
                        <span class="paper-venue">IEEE Xplorer ¬∑ 2021</span>
                        <h3>Visual-based real time driver drowsiness detection system using CNN</h3>
                        <p>Propuesta de un framework end-to-end dise√±ado para entornos de baja iluminaci√≥n utilizando grafos de atenci√≥n.</p>
                        <div class="paper-actions">
                            <a href="https://ieeexplore.ieee.org/abstract/document/9633082" class="paper-link pdf">PDF</a>
                            <!-- <a href="https://github.com/JonathanFlores2503/TransLowNET_FinalVersion" class="paper-link code">Code</a> -->
                            <button class="paper-link bib" onclick="copyBib_11()">BibTeX</button>
                        </div>
                    </div>
                    <div class="paper-stats">
                        <div class="stat-item">
                            <span class="stat-value">SOTA</span>
                            <span class="stat-label">Model</span>
                        </div>
                    </div>
                </article>











































                </div>
        </section>


    <section id="db-section" class="db-preview">
        <h2>Custom Dataset Development</h2>
        <p>Curaci√≥n de 500+ horas de video para anomal√≠as en transporte p√∫blico mexicano.</p>
        <div class="db-grid">
            <div class="db-item">Sample 1</div>
            <div class="db-item">Sample 2</div>
            <div class="db-item">Sample 3</div>
        </div>
    </section>


        <!-- <section id="achievements" class="achievements-section">
            <h2 class="section-title">Achievements & Recognition</h2>
            
            <div class="achievement-grid">
                <div class="achievement-card">
                    <span class="icon">üèÜ</span> <h3>Future Award: [Nombre de la Presea]</h3>
                    <p>Prepar√°ndome para competir por la prestigiosa presea, reflejando la innovaci√≥n en IA aplicada.</p>
                    <span class="status coming-soon">Goal for 202X</span>
                </div>

                <div class="achievement-card">
                    <span class="icon">üí°</span> <h3>Patent Granted: [Nombre de la Patente 1]</h3>
                    <p>M√©todo novedoso para la detecci√≥n temprana de anomal√≠as en redes de transporte p√∫blico.</p>
                    <span class="status granted">Granted 2023</span>
                </div>

                <div class="achievement-card">
                    <span class="icon">üìù</span> <h3>Patent Pending: [Nombre de la Patente 2]</h3>
                    <p>Arquitectura optimizada para procesamiento de video en tiempo real en dispositivos Edge AI.</p>
                    <span class="status pending">Pending Review</span>
                </div>
                
                </div>
        </section> -->


        <section id="awards" class="awards-section">
            <h2 class="section-title">Awards & Honors</h2>
            <div class="awards-container">

                <div class="award-item highlight">
                    <div class="award-date">2027</div>
                    <div class="award-info">
                        <h3>[Nombre de la Presea]</h3>
                        <p>Candidato/Finalista por impacto tecnol√≥gico en la Ciudad de M√©xico.</p>
                        <span class="badge-gold">En Proceso</span>
                    </div>
                </div>

                <div class="award-item">
                    <div class="award-date">2027</div>
                    <div class="award-info">
                        <h3>Menci√≥n Honor√≠fica - PhD Defense</h3>
                        <p>Reconocimiento a la excelencia acad√©mica y aporte cient√≠fico en el √°rea de Computer Vision.</p>
                    </div>
                </div>
                
                <div class="award-item">
                    <div class="award-date">2026</div>
                    <div class="award-info">
                        <h3>Best Research Proposal</h3>
                        <p>Otorgado por [Instituci√≥n/Conferencia] por la innovaci√≥n en modelos GNN para transporte p√∫blico.</p>
                        <a href="gallery.html#gallery" class="view-photo">Ver en Galer√≠a ‚Üí</a>
                    </div>
                </div>

                <div class="award-item">
                    <div class="award-date">2024</div>
                    <div class="award-info">
                        <h3>MEjor de la Generacion de intergacion MExico-JApon</h3>
                        <p>Otorgado por [Instituci√≥n/Conferencia] por la innovaci√≥n en modelos GNN para transporte p√∫blico.</p>
                        <a href="gallery.html#gallery" class="view-photo">Ver en Galer√≠a ‚Üí</a>
                    </div>
                </div>

            
                <div class="award-item">
                    <div class="award-date">2022</div>
                    <div class="award-info">
                        <h3>Menci√≥n Honor√≠fica - MsC Defense</h3>
                        <p>Reconocimiento a la excelencia acad√©mica y aporte cient√≠fico en el √°rea de Computer Vision.</p>
                    </div>
                </div>

                <div class="award-item">
                    <div class="award-date">2022</div>
                    <div class="award-info">
                        <h3>Patente</h3>
                        <p>Reconocimiento a la excelencia acad√©mica y aporte cient√≠fico en el √°rea de Computer Vision.</p>
                    </div>
                </div>

                

            </div>
        </section>

        <footer>
            <p>&copy; 2026 Jonathan Flores Monroy - Applied AI Researcher</p>
        </footer>

        <script src="research.js"></script>

    </body>
</html>

</body>
</html>